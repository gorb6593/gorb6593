1. ! 제거 하기 jar파일 설치

[오늘 할일]
1. Ajax로 받은 결과 마무리
2. 빅데이터 플랫폼 구축
   1)VMWare설치
   2)CentOS설치
   3)머신4대 설치
   4)클러스터링
     	4대를 연결(주로 머신1에서 ssh통신을 이용해서 원격으로 접속해서 작업)
	ssh(Secure shell)
	:텔넷과 비슷한 개념
	서버와 클라이언트간의 텍스트기반 통신
	하둡도 내부에서 ssh프로토콜을 이용해서 통신, 암호화해서 통신하기 위한 프로토콜

     	4대를 식별하기 위해서 host명 변경
	hostnamectl set-hostname 변경하고 싶은 호스트명
	방화벽해제	
	systemctl disable firewalld
	-도메인등록
	ssh통신을 하기 위해 hadoop01에서 나머지 머신을 접근
	ip로 접근하기 불편하므로 호스트명을 등록해서 작업
	/etc/hosts파일 수정

[프로그램설치]
1)자바설치
-jdk설치

2)하둡설치
-1.x
-2.x
-3.x

3)ssh프로토콜로 암호통신을 할 수 있도록 설정하기
- 하둡 내부에서 ssh통신을 하기 때문에 통신할 수 있도록

4)하둡설정

4)하둡프로그래밍
-hdfs
-mapreduce
-고급프로그래밍(customizing)

5)하둡에코시스텀 설치 후 테스트
-flume
-sqoop
-hive
-pig
-mahout

6)R

   하둡설치 및 설정
      -네이워크 구성
   5)login처리

[빅데이터]
- Ajax로 요청한 데이터를 정리해서 출력
- 빅데이터 플랫폼 구축

VMWare설치
OS설치(CentOS - 시스템을 자동으로 실행되도록 처리)
설정
hadoop설치
hadoop EcoSystem(하둡과 연관된 프로그램 설치하고 사용)
	:sqoop, flume, hive, pig
원하는 작업을 할 수 있도록 프로그래밍
분석결과 활용(R, Mahout)
	----------------
	추천시스템

정리 필수 -> 설치과정이 너무 까다롭다 


1. VMWare 설치하는 법
https://www.vmware.com 들어가서 player버전 받기
다운 후 bigdata_iot로 가져와서 진행
진행할때 특이 사항없는거는 next 누르기

- custom Setup에서 두 항목 체크하고 next
- 그 다음 페이지는 두 항목 체크해제 하고 next
finish하고 재부팅까지 하면 끝

--혹시문제가 생겨 삭제해야 한다면 오라클과 마찬가지로 기존 설치파일을 눌러서 삭제해야 한다(remove)

2. VMwareWorkstation 16 Player 실행

linux , centos07 64bit
컴퓨터 추가하고 single file로 설정하고 next

네트워크를 위한 설정 파일복사(vmnetcfg.exe) 이 파일을 카페에서 다운받고 VMware Player에 가져놓고 버전 동일하게 맞추기

1~4번 켜기 loot/bigdata

hadoop01 ip => 192.168.111.129
hadoop02 ip => 192.168.111.128 
hadoop03 ip => 192.168.111.130
hadoop04 ip => 192.168.111.131

이름 바꾸기 hostnamectl set-hostname 바꿀이름
systemctl list-units --type-sercvice
ctrl + c 빠져나오기
systemctl stop firewalld

\\192.168.0.221 

root계정 : /root
일반계정 : /home/계정명

-a

/home : 사용자 계정의 홈디렉토리
/boot : 부팅에 필요한 각종 설정파일이 위치하는 곳
/root : root계정의 홈디렉토리
/bin : 리눅스에서 사용할 수 있는 shell명령어가 위치하는 곳
/sbin : 시스템관리를 위한 명령어가 위치
/etc : 시스템관리를 위한 설정파일이 위치하는 디렉토리 / 사용자 정보, 파일시스템 정보, 네트워크 정보
/tmp : 시스템이 작업 중 사용하는 임시 폴더
/var : tmp와 유사, 보통 로그 파일이 위치
/lib : 공통 라이브러리파일이 저장되는 위치
/dev : 장치가 위치하는 디렉토리 - 리눅스는 모든 장치를 파일로 인식
/usr : 윈도우의 program files와 동일


rpm 명령어
-U : 이전 버전이 있으면 업그레이드
-v : 설치되는 과정을 보여주기
-h : 설치과정에 #을 추가하기

1. /home/hadoop/hadoop-1.2.1/conf폴더에서 설정파일 확인
2. 수정하고 세 대의 머신에 scp로 copy
3. hadoop을 다시 start-all.sh
4. 데몬 확인(jps)
   모두 동일하게 실행

1번 - namenode, jobtracker
2번 - secondarynamenode, datanode, tasktracker
3번,4번 - datanode, tasktracker


5. 1번부터 4번까지 실행 후 데몬이 정상 실행되지 않는 경우
   1번 ~4번 노드의 hadoop-data를 모두 삭제
6. 1번 머신의 hadoop계정에서 hadoop-data디렉토리 mkdir
7. namenode초기화
8. start-all.sh 후 jps로 데몬확인

